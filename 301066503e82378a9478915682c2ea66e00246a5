{
  "comments": [
    {
      "key": {
        "uuid": "1a494da4_ee6702e9",
        "filename": "jjb/dovetail/dovetail-run.sh",
        "patchSetId": 2
      },
      "lineNbr": 137,
      "author": {
        "id": 2997
      },
      "writtenOn": "2018-05-22T14:13:49Z",
      "side": 1,
      "message": "IPMI user/pass for jumpserver are not necessarily the same with the credentials for the cluster nodes.\nInstead, user/pass should be read for each node individually ...",
      "range": {
        "startLine": 136,
        "startChar": 0,
        "endLine": 137,
        "endChar": 78
      },
      "revId": "301066503e82378a9478915682c2ea66e00246a5",
      "serverId": "bbac25d2-bf60-4904-9ba8-a72fc000d6c5",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "1a494da4_89463822",
        "filename": "jjb/dovetail/dovetail-run.sh",
        "patchSetId": 2
      },
      "lineNbr": 137,
      "author": {
        "id": 5469
      },
      "writtenOn": "2018-05-23T06:21:23Z",
      "side": 1,
      "message": "Yes. I agree.\nBut from all PDFs in pharos, they all only give the JumpHost user and password. There is no user and password given for each node.(especially for the PODs Dovetail will use)\nI guess that they all use the same user and password. Am I right?\nSo I just read the JumpHost info rather than every node\u0027s info here.",
      "parentUuid": "1a494da4_ee6702e9",
      "range": {
        "startLine": 136,
        "startChar": 0,
        "endLine": 137,
        "endChar": 78
      },
      "revId": "301066503e82378a9478915682c2ea66e00246a5",
      "serverId": "bbac25d2-bf60-4904-9ba8-a72fc000d6c5",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "1a494da4_d09f4002",
        "filename": "jjb/dovetail/dovetail-run.sh",
        "patchSetId": 2
      },
      "lineNbr": 137,
      "author": {
        "id": 6819
      },
      "writtenOn": "2018-05-24T11:38:10Z",
      "side": 1,
      "message": "There is a user and password ipmi information under each node. Generally they are the same and that is why this info is left under \"remote_params\" and then referenced. Instead of using that variable, read it from the node itself:\n\njumphost.remote_management.pass\njumphost.remote_management.user\nnodes.$i.remote_management.pass\nnodes.$i.remote_management.user",
      "parentUuid": "1a494da4_89463822",
      "range": {
        "startLine": 136,
        "startChar": 0,
        "endLine": 137,
        "endChar": 78
      },
      "revId": "301066503e82378a9478915682c2ea66e00246a5",
      "serverId": "bbac25d2-bf60-4904-9ba8-a72fc000d6c5",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "1a494da4_0e5fce0f",
        "filename": "jjb/dovetail/dovetail-run.sh",
        "patchSetId": 2
      },
      "lineNbr": 140,
      "author": {
        "id": 2997
      },
      "writtenOn": "2018-05-22T14:13:49Z",
      "side": 1,
      "message": "this should be dynamic. noha scenarios on baremetal don\u0027t necessarily use all 5 nodes",
      "range": {
        "startLine": 140,
        "startChar": 15,
        "endLine": 140,
        "endChar": 16
      },
      "revId": "301066503e82378a9478915682c2ea66e00246a5",
      "serverId": "bbac25d2-bf60-4904-9ba8-a72fc000d6c5",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "1a494da4_e94a5c26",
        "filename": "jjb/dovetail/dovetail-run.sh",
        "patchSetId": 2
      },
      "lineNbr": 140,
      "author": {
        "id": 5469
      },
      "writtenOn": "2018-05-23T06:21:23Z",
      "side": 1,
      "message": "Good suggestion. Will try to set the number to be the exactly node number in PDF.",
      "parentUuid": "1a494da4_0e5fce0f",
      "range": {
        "startLine": 140,
        "startChar": 15,
        "endLine": 140,
        "endChar": 16
      },
      "revId": "301066503e82378a9478915682c2ea66e00246a5",
      "serverId": "bbac25d2-bf60-4904-9ba8-a72fc000d6c5",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "1a494da4_0eb6ae3d",
        "filename": "jjb/dovetail/dovetail-run.sh",
        "patchSetId": 2
      },
      "lineNbr": 143,
      "author": {
        "id": 2997
      },
      "writtenOn": "2018-05-22T14:13:49Z",
      "side": 1,
      "message": "I really don\u0027t understand what this is supposed to do.\nFirst of all, note that IPMI MAC:\n- is not usually set in PDF for most PODs;\n- is not visible in Linux via `ip a`, as IPMI uses a dedicated interface;\nThen, this seems to look for a node IPMI MAC on the cfg01 (Salt Master) node, which will probably never succeed ...",
      "range": {
        "startLine": 142,
        "startChar": 0,
        "endLine": 143,
        "endChar": 108
      },
      "revId": "301066503e82378a9478915682c2ea66e00246a5",
      "serverId": "bbac25d2-bf60-4904-9ba8-a72fc000d6c5",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "1a494da4_c9f5e0cc",
        "filename": "jjb/dovetail/dovetail-run.sh",
        "patchSetId": 2
      },
      "lineNbr": 143,
      "author": {
        "id": 5469
      },
      "writtenOn": "2018-05-23T06:21:23Z",
      "side": 1,
      "message": "Line 130 gets a controller ip \u0027fuel_ctl_ip\u0027, then it needs to find its IMPI IP from the PDF. Here is trying to do that.\nI though it can be filtered out according to the MAC address. But it seems that I am wrong.\nDo you have any idea about this? How can I get the IPMI IP according to \u0027fuel_ctl_ip\u0027?",
      "parentUuid": "1a494da4_0eb6ae3d",
      "range": {
        "startLine": 142,
        "startChar": 0,
        "endLine": 143,
        "endChar": 108
      },
      "revId": "301066503e82378a9478915682c2ea66e00246a5",
      "serverId": "bbac25d2-bf60-4904-9ba8-a72fc000d6c5",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "1a494da4_b07274e3",
        "filename": "jjb/dovetail/dovetail-run.sh",
        "patchSetId": 2
      },
      "lineNbr": 143,
      "author": {
        "id": 6819
      },
      "writtenOn": "2018-05-24T11:38:10Z",
      "side": 1,
      "message": "Controllers in fuel are normally VMs running on top of the servers described on the PDF. Line 130 get you the ip of one of them (actually all of them, then filtered by awk), but as VMs they dont relate to the server IPMI described on the PDF. \n\nDepending on what actions you need to with that there may be other ways to interact with the controller vms or vm host",
      "parentUuid": "1a494da4_c9f5e0cc",
      "range": {
        "startLine": 142,
        "startChar": 0,
        "endLine": 143,
        "endChar": 108
      },
      "revId": "301066503e82378a9478915682c2ea66e00246a5",
      "serverId": "bbac25d2-bf60-4904-9ba8-a72fc000d6c5",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "1a494da4_8118cc85",
        "filename": "jjb/dovetail/dovetail-run.sh",
        "patchSetId": 2
      },
      "lineNbr": 143,
      "author": {
        "id": 5469
      },
      "writtenOn": "2018-05-26T01:38:00Z",
      "side": 1,
      "message": "Thanks for your comments. The actions that one Yardstick test case needs to do here is using ipmi info to log in a controller node and then shut it down. By doing this, it can monitor that whether the openstack service can work well. Before the end of the test, it will power on this node.\nAll this test case needs is the ipmi info of one controller node.",
      "parentUuid": "1a494da4_b07274e3",
      "range": {
        "startLine": 142,
        "startChar": 0,
        "endLine": 143,
        "endChar": 108
      },
      "revId": "301066503e82378a9478915682c2ea66e00246a5",
      "serverId": "bbac25d2-bf60-4904-9ba8-a72fc000d6c5",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "1a494da4_19742cce",
        "filename": "jjb/dovetail/dovetail-run.sh",
        "patchSetId": 2
      },
      "lineNbr": 143,
      "author": {
        "id": 6819
      },
      "writtenOn": "2018-05-30T15:11:50Z",
      "side": 1,
      "message": "In this case it would be easier to shut down the physical node even if the openstack controller is a VM into it.\n\nNormally there would be 3 controller VMs (ctl01 ctl02 ctl03) sharing a floating virtual IP. Each VM runs on a different baremetal node (kvm01 kvm02 kvm03)\n\nYou could ask for the control VIP getting the param _param:openstack_control_address as you did on line 131.  Only one node has that IP active so you can find out which one is the active filtering with that ip. The answer will have the master ctl host name and this can be trimmed to an N integer. \n\nThis integer could be used to point to the list of nodes of the pdf as you had there with $i but keep in mind this one goes from 1 to 3 and not 0 to 2. \n\n\nubuntu@cfg01:~$ sudo salt \"cfg*\" pillar.get _param:openstack_control_address --out text | cut -f 2 -d \" \"\n172.16.10.35\n\nubuntu@cfg01:~$ sudo salt \"ctl*\" network.ip_addrs cidr\u003d172.16.10.35  --out text | grep \"172.16.10.35\" | cut -c 5\n3\n\ncontrol address\u003d 172.16.10.35\nN\u003d3 (ctl03, 3rd baremetal node)\nnodes.(N-1).remote_management.address",
      "parentUuid": "1a494da4_8118cc85",
      "range": {
        "startLine": 142,
        "startChar": 0,
        "endLine": 143,
        "endChar": 108
      },
      "revId": "301066503e82378a9478915682c2ea66e00246a5",
      "serverId": "bbac25d2-bf60-4904-9ba8-a72fc000d6c5",
      "unresolved": false
    }
  ]
}