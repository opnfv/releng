---
###################################
# job configuration for cperf
###################################
- project:
    name: cperf-ci-jobs
    project: cperf

    # -------------------------------
    # BRANCH ANCHORS
    # -------------------------------
    master: &master
      stream: master
      branch: '{stream}'
      gs-pathname: ''
      docker-tag: 'latest'
    danube: &danube
      stream: danube
      branch: 'stable/{stream}'
      gs-pathname: '/{stream}'
      docker-tag: 'stable'

    # -------------------------------
    # POD, INSTALLER, AND BRANCH MAPPING
    # -------------------------------
    pod:
      # -------------------------------
      #        master
      # -------------------------------
      - intel-pod2:
          installer: apex
          <<: *master
      - intel-pod2:
          installer: apex
          <<: *danube

    testsuite:
      - 'daily'

    jobs:
      - 'cperf-{installer}-{pod}-{testsuite}-{stream}'

################################
# job template
################################
- job-template:
    name: 'cperf-{installer}-{pod}-{testsuite}-{stream}'

    concurrent: true

    properties:
      - logrotate-default
      - throttle:
          enabled: true
          max-per-node: 1
          option: 'project'

    wrappers:
      - build-name:
          name: '$BUILD_NUMBER Suite: $CPERF_SUITE_NAME Scenario: $DEPLOY_SCENARIO'
      - timeout:
          timeout: 400
          abort: true

    parameters:
      - project-parameter:
          project: '{project}'
          branch: '{branch}'
      - '{pod}-defaults'
      - '{installer}-defaults'
      - cperf-parameter:
          testsuite: '{testsuite}'
          gs-pathname: '{gs-pathname}'
          docker-tag: '{docker-tag}'

    scm:
      - git-scm

    builders:
      - 'cperf-{testsuite}-builder'

########################
# parameter macros
########################
- parameter:
    name: cperf-parameter
    parameters:
      - string:
          name: CPERF_SUITE_NAME
          default: '{testsuite}'
          description: "Suite name to run"
      - string:
          name: GS_PATHNAME
          default: '{gs-pathname}'
          description: "Version directory where the opnfv documents will be stored in gs repository"
      - string:
          name: CI_DEBUG
          default: 'false'
          description: "Show debug output information"
      - string:
          name: DOCKER_TAG
          default: '{docker-tag}'
          description: 'Tag to pull docker image'

########################
# trigger macros
########################

########################
# builder macros
########################
- builder:
    name: cperf-daily-builder
    builders:
      - 'cperf-cleanup'
      - 'cperf-prepare-robot'
      - 'cperf-robot-netvirt-csit'

- builder:
    name: cperf-prepare-robot
    builders:
      - shell: |
          #!/bin/bash
          set -o errexit
          set -o nounset
          set -o pipefail
          undercloud_mac=$(sudo virsh domiflist undercloud | grep default | \
                            grep -Eo "[0-9a-f]+:[0-9a-f]+:[0-9a-f]+:[0-9a-f]+:[0-9a-f]+:[0-9a-f]+")
          INSTALLER_IP=$(/usr/sbin/arp -e | grep ${undercloud_mac} | awk {'print $1'})

          sudo scp -o StrictHostKeyChecking=no root@$INSTALLER_IP:/home/stack/overcloudrc /tmp/overcloudrc
          sudo chmod 755 /tmp/overcloudrc
          source /tmp/overcloudrc

          # robot suites need the ssh key to log in to controller nodes, so throwing it
          # in tmp, and mounting /tmp as $HOME as far as robot is concerned
          sudo rm -rf /tmp/.ssh
          sudo mkdir /tmp/.ssh
          sudo chmod 0700 /tmp/.ssh
          sudo scp -o StrictHostKeyChecking=no root@$INSTALLER_IP:/home/stack/.ssh/id_rsa /tmp/.ssh/
          sudo chown -R jenkins-ci:jenkins-ci /tmp/.ssh
          # done with sudo. jenkins-ci is the user from this point
          chmod 0600 /tmp/.ssh/id_rsa

          # cbench requires the openflow drop test feature to be installed.
          sshpass -p karaf ssh -o StrictHostKeyChecking=no \
                               -o UserKnownHostsFile=/dev/null \
                               -o LogLevel=error \
                               -p 8101 karaf@$SDN_CONTROLLER_IP \
                                feature:install odl-openflowplugin-flow-services-ui odl-openflowplugin-drop-test

          docker pull opnfv/cperf:$DOCKER_TAG

          sudo mkdir -p /tmp/robot_results

- builder:
    name: cperf-robot-cbench
    builders:
      - shell: |
          #!/bin/bash
          set -o errexit
          set -o nounset
          set -o pipefail

          robot_cmd="pybot -e exclude -L TRACE -d /tmp \
                      -v ODL_SYSTEM_1_IP:${SDN_CONTROLLER_IP} \
                      -v ODL_SYSTEM_IP:${SDN_CONTROLLER_IP} \
                      -v BUNDLEFOLDER:/opt/opendaylight \
                      -v RESTCONFPORT:8081 \
                      -v USER_HOME:/tmp \
                      -v USER:heat-admin \
                      -v ODL_SYSTEM_USER:heat-admin \
                      -v TOOLS_SYSTEM_IP:localhost \
                      -v of_port:6653"
          robot_suite="/home/opnfv/repos/odl_test/csit/suites/openflowplugin/Performance/010_Cbench.robot"

          docker run -i -v /tmp:/tmp opnfv/cperf:$DOCKER_TAG ${robot_cmd} ${robot_suite}

- builder:
    name: cperf-robot-netvirt-csit
    builders:
      - shell: |
          #!/bin/bash
          set -o errexit
          set -o nounset
          set -o pipefail
          source {{ overcloudrc }}
          STACK_HOME=~stack
          robot_cmd="pybot \
                        --removekeywords wuks \
                        --xunit robotxunit.xml \
                        -c critical \
                        -e exclude \
                        -d /tmp/robot_results \
                        -v BUNDLEFOLDER:/opt/opendaylight \
                        -v CONTROLLER_USER:heat-admin \
                        -v DEFAULT_LINUX_PROMPT:\$ \
                        -v DEFAULT_LINUX_PROMPT_STRICT:]\$ \
                        -v DEFAULT_USER:heat-admin \
                        -v DEVSTACK_DEPLOY_PATH:/tmp \
                        -v HA_PROXY_IP:$ODL_IP \
                        -v HA_PROXY_1_IP:$ODL_IP \
                        -v HA_PROXY_2_IP:$ODL_IP \
                        -v HA_PROXY_3_IP:$ODL_IP \
                        -v NUM_ODL_SYSTEM:3 \
                        -v NUM_OS_SYSTEM:3 \
                        -v NUM_TOOLS_SYSTEM:0 \
                        -v ODL_SNAT_MODE:conntrack \
                        -v ODL_STREAM:fluorine \
                        -v ODL_SYSTEM_IP:$ODL_IP \
                        -v ODL_SYSTEM_1_IP:$ODL_IP \
                        -v OS_CONTROL_NODE_IP:$ODL_IP \
                        -v OS_CONTROL_NODE_1_IP:$OPENSTACK_CONTROL_NODE_1_IP \
                        -v OS_CONTROL_NODE_2_IP:$OPENSTACK_CONTROL_NODE_2_IP \
                        -v OS_CONTROL_NODE_3_IP:$OPENSTACK_CONTROL_NODE_3_IP \
                        -v OPENSTACK_BRANCH:stable/queens \
                        -v OS_COMPUTE_1_IP:$OPENSTACK_COMPUTE_NODE_1_IP \
                        -v OS_COMPUTE_2_IP:$OPENSTACK_COMPUTE_NODE_2_IP \
                        -v ODL_SYSTEM_IP:$OPENSTACK_CONTROL_NODE_1_IP \
                        -v ODL_SYSTEM_1_IP:$OPENSTACK_CONTROL_NODE_1_IP \
                        -v ODL_SYSTEM_2_IP:$OPENSTACK_CONTROL_NODE_2_IP \
                        -v ODL_SYSTEM_3_IP:$OPENSTACK_CONTROL_NODE_3_IP \
                        -v OS_USER:heat-admin \
                        -v ODL_ENABLE_L3_FWD:yes \
                        -v ODL_SYSTEM_USER:heat-admin \
                        -v ODL_SYSTEM_PROMPT:\$ \
                        -v PRE_CLEAN_OPENSTACK_ALL:True \
                        -v PUBLIC_PHYSICAL_NETWORK:datacentre \
                        -v RESTCONFPORT:8081 \
                        -v ODL_RESTCONF_USER:admin \
                        -v ODL_RESTCONF_PASSWORD:admin \
                        -v KARAF_PROMPT_LOGIN:'opendaylight-user' \
                        -v KARAF_PROMPT:'opendaylight-user.*root.*>' \
                        -v SECURITY_GROUP_MODE:stateful \
                        -v USER_HOME:/home/stack \
                        -v WORKSPACE:{{ workdir }}/workspace  \
                        -v USER:heat-admin \
                        -v TOOLS_SYSTEM_IP:localhost \
                        -v NODE_KARAF_COUNT_COMMAND:\"sudo docker exec opendaylight_api /bin/bash -c 'ps axf | grep org.apache.karaf | grep -v grep | wc -l' || echo 0\" \
                        -v NODE_START_COMMAND:\"sudo docker start opendaylight_api\" \
                        -v NODE_KILL_COMMAND:\"sudo docker stop opendaylight_api\" \
                        -v NODE_STOP_COMMAND:\"sudo docker stop opendaylight_api\" \
                        -v NODE_FREEZE_COMMAND:\"sudo docker stop opendaylight_api\" \
                        -v NODE_ROLE_INDEX_START:0 \
                        -v of_port:6653 "

          docker run -i --net=host -v {{ workdir }}:{{ workdir }}:Z \
                                   -v /home/stack/.ssh:/home/stack/.ssh:Z \
                                   -v $STACK_HOME:$STACK_HOME \
                                   -v {{ overcloudrc }}:{{ overcloudrc }} \
                                   {{ test.container.image.name }} \
                        /bin/bash -c "source {{ overcloudrc }}; \
                                      $robot_cmd /home/opnfv/repos/odl_test/csit/suites/openstack/connectivity/l2.robot;"

- builder:
    name: cperf-cleanup
    builders:
      - shell: |
          #!/bin/bash
          [[ $CI_DEBUG == true ]] && redirect="/dev/stdout" || redirect="/dev/null"

          echo "Cleaning up docker containers/images..."
          # Remove previous running containers if exist
          if [[ ! -z $(docker ps -a | grep opnfv/cperf) ]]; then
              echo "Removing existing opnfv/cperf containers..."
              docker ps -a | grep opnfv/cperf | awk '{print $1}' | xargs docker rm -f >${redirect}
          fi

          # Remove existing images if exist
          if [[ ! -z $(docker images | grep opnfv/cperf) ]]; then
              echo "Docker images to remove:"
              docker images | head -1 && docker images | grep opnfv/cperf >${redirect}
              image_tags=($(docker images | grep opnfv/cperf | awk '{print $2}'))
              for tag in "${image_tags[@]}"; do
                  echo "Removing docker image opnfv/cperf:$tag..."
                  docker rmi opnfv/cperf:$tag >/dev/null
              done
          fi
